{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import copy\n",
    "import warnings\n",
    "import gc\n",
    "from sklearn import preprocessing\n",
    "warnings.filterwarnings('ignore')\n",
    "feature_path ='./feature/'\n",
    "res_path = './res/'\n",
    "data_path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transaction_df = pd.read_csv(data_path+'transaction_train_new.csv')\n",
    "operation_df =  pd.read_csv(data_path+'operation_train_new.csv')\n",
    "label= pd.read_csv(data_path+'tag_train_new.csv')\n",
    "\n",
    "transaction_test = pd.read_csv(data_path+'transaction_round1_new.csv')\n",
    "operation_test = pd.read_csv(data_path+'operation_round1_new.csv')\n",
    "sample = pd.read_csv(data_path+'sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_count(df1,df2,columns,value,cname):\n",
    "    add = df1.groupby(columns)[value].count().reset_index().rename(columns = {value:cname})\n",
    "    df2=df2.merge(add,on=columns,how=\"left\")\n",
    "    del add\n",
    "    gc.collect()\n",
    "    return df2\n",
    "\n",
    "def merge_nunique(df1,df2,columns,value,cname):\n",
    "    add = df1.groupby(columns)[value].nunique().reset_index().rename(columns = {value:cname})\n",
    "    df2=df2.merge(add,on=columns,how=\"left\")\n",
    "    del add\n",
    "    gc.collect()\n",
    "    return df2\n",
    "\n",
    "def merge_value_count(df1,df2,col,value):\n",
    "    tmp = df1.groupby(col)[value].count().reset_index().rename(columns = {value:'cnt'})\n",
    "    df = tmp.pivot(index=col[0],columns=col[1],values='cnt').reset_index()\n",
    "    cname = [col[0]]\n",
    "    for index in range(1,len(df.columns)):\n",
    "        cname.append(str(col[1])+'_'+str(df.columns[index]))\n",
    "    df.columns=cname\n",
    "    df = df.fillna(0)\n",
    "    df2 = df2.merge(df,on=str(col[0]),how='left')\n",
    "    del df,df1\n",
    "    gc.collect()\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_op_fea(operation_df):\n",
    "    #op_day\n",
    "    op_fea = operation_df[['UID']].drop_duplicates()\n",
    "    tmp = operation_df.groupby('UID')['day'].agg([max,min,np.mean]).reset_index()\n",
    "    tmp.columns=['UID','op_day_max','op_day_min','op_day_mean']\n",
    "    op_fea = pd.merge(op_fea,tmp,on='UID',how='left')\n",
    "    #op_mode count\n",
    "    op_fea = merge_count(operation_df,op_fea,'UID','mode','op_cnt')\n",
    "    op_fea = merge_nunique(operation_df,op_fea,'UID','mode','op_mode_nunique')\n",
    "    #success count\n",
    "    op_fea = merge_count(operation_df[operation_df.success==0],op_fea,'UID','mode','op_fail_cnt')\n",
    "    op_fea = merge_count(operation_df[operation_df.success==1],op_fea,'UID','mode','op_success_cnt')\n",
    "    op_fea['op_fail_cnt'] = op_fea['op_fail_cnt'].fillna(0)\n",
    "    op_fea['op_success_cnt'] = op_fea['op_success_cnt'].fillna(0)\n",
    "    #op_time\n",
    "    operation_df['op_hour'] = operation_df['time'].apply(lambda x:int(x.split(':')[0]))\n",
    "    tmp = operation_df.groupby('UID')['op_hour'].agg([max,min,np.mean]).reset_index()\n",
    "    tmp.columns=['UID','op_hour_max','op_hour_min','op_hour_mean']\n",
    "    op_fea = pd.merge(op_fea,tmp,on='UID',how='left')\n",
    "    #op_os\n",
    "    for col in ['os','version','device1','device2','device_code1','device_code2','mac1','ip1','ip2','device_code3','mac2','wifi','geo_code','ip1_sub','ip2_sub']:\n",
    "        op_fea = merge_nunique(operation_df,op_fea,'UID',col,'op_'+col+'_nunique')\n",
    "    return op_fea\n",
    "\n",
    "def get_trans_fea(transaction_df):\n",
    "    trans_fea = transaction_df[['UID']].drop_duplicates()\n",
    "    #trans_channel\n",
    "    trans_fea = merge_value_count(transaction_df,trans_fea,['UID','channel'],'day')\n",
    "    trans_fea = merge_count(transaction_df,trans_fea,'UID','channel','trans_cnt')\n",
    "    trans_fea = merge_nunique(transaction_df,trans_fea,'UID','channel','trans_channel_nunique')\n",
    "\n",
    "    for col in ['trans_type2','market_type']:\n",
    "        trans_fea = merge_value_count(transaction_df,trans_fea,['UID',col],'day')\n",
    "        trans_fea = merge_nunique(transaction_df,trans_fea,'UID',col,'trans_'+col+'_nunique')\n",
    "    for col in ['trans_type1','merchant','code1','code2','acc_id1','device_code1','device_code2','device_code3','device1','device2','mac1','ip1','acc_id2','acc_id3','geo_code','market_code','ip1_sub']:\n",
    "        trans_fea = merge_nunique(transaction_df,trans_fea,'UID',col,'trans_'+col+'_nunique')\n",
    "    return trans_fea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "#train xgb\n",
    "config = {\n",
    "    'rounds': 10000,\n",
    "    'folds': 5\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'booster':'gbtree',\n",
    "    'objective':'binary:logistic',\n",
    "    'stratified':True,\n",
    "    'max_depth':5,\n",
    "    'min_child_weight':1,\n",
    "    'gamma':3,\n",
    "    'subsample':0.8,#0.7\n",
    "    'colsample_bytree':0.6, \n",
    "    'lambda':3, \n",
    "    'eta':0.05,\n",
    "    'seed':20,\n",
    "    'silent':1,\n",
    "    'eval_metric':'auc'\n",
    "}\n",
    "\n",
    "def customedscore1(preds, dtrain):\n",
    "    label = dtrain.get_label()\n",
    "    d = pd.DataFrame()\n",
    "    d['prob'] = list(preds)\n",
    "    d['y'] = list(label)\n",
    "    d = d.sort_values(['prob'], ascending=[0])\n",
    "    y = d.y\n",
    "    PosAll = pd.Series(y).value_counts()[1]\n",
    "    NegAll = pd.Series(y).value_counts()[0]\n",
    "    \n",
    "    pCumsum = d['y'].cumsum()\n",
    "    nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "    pCumsumPer = pCumsum / PosAll\n",
    "    nCumsumPer = nCumsum / NegAll\n",
    "    \n",
    "    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "    score = 0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3\n",
    "    return 'SCORE',float(score)\n",
    "\n",
    "\n",
    "def xgbCV(trainFeature, trainLabel, params, rounds):\n",
    "\n",
    "    dtrain = xgb.DMatrix(trainFeature, label = trainLabel)\n",
    "    params['scale_pos_weights '] = (float)(len(trainLabel[trainLabel == 0]))/(float)(len(trainLabel[trainLabel == 1]))\n",
    "    num_round =rounds\n",
    "    print ('run cv: ' + 'round: ' + str(rounds))\n",
    "    res = xgb.cv(params, dtrain, num_round, verbose_eval = 100,early_stopping_rounds=200,nfold=3,feval = customedscore1)\n",
    "    return res\n",
    "\n",
    "def xgbPredict(trainFeature,trainLabel,testFeature,rounds,params):\n",
    "    params['scale_pos_weights '] = (float)(len(trainLabel[trainLabel == 0]))/len(trainLabel[trainLabel == 1])\n",
    "    \n",
    "    dtrain = xgb.DMatrix(trainFeature.values, label = trainLabel)\n",
    "    dtest = xgb.DMatrix(testFeature.values)\n",
    "\n",
    "    watchlist  = [(dtrain,'train')]\n",
    "    num_round = rounds\n",
    "    \n",
    "    model = xgb.train(params, dtrain, num_round, watchlist, verbose_eval = 50,feval = customedscore1)\n",
    "    predict = model.predict(dtest)\n",
    "    return model,predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "op_fea = get_op_fea(operation_df)\n",
    "trans_fea = get_trans_fea(transaction_df)\n",
    "\n",
    "op_fea_test = get_op_fea(operation_test)\n",
    "trans_fea_test = get_trans_fea(transaction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_fea = trans_fea.merge(op_fea,on='UID',how='outer')\n",
    "trainData = all_fea.merge(label,on='UID',how='left')\n",
    "trainFeature = trainData.drop(['Tag','UID'],axis=1)\n",
    "trainLabel = trainData.Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run cv: round: 10000\n",
      "[0]\ttrain-SCORE:0.401762+0.0729671\ttrain-auc:0.938601+0.00894842\ttest-SCORE:0.364175+0.0470441\ttest-auc:0.933516+0.00897566\n",
      "[100]\ttrain-SCORE:0.869608+0.0151333\ttrain-auc:0.995377+0.000640134\ttest-SCORE:0.752132+0.0125843\ttest-auc:0.991154+0.00117751\n",
      "[200]\ttrain-SCORE:0.928019+0.00902273\ttrain-auc:0.998277+0.000143885\ttest-SCORE:0.787762+0.0279574\ttest-auc:0.993611+0.00139236\n",
      "[300]\ttrain-SCORE:0.946256+0.00403146\ttrain-auc:0.998892+4.80578e-05\ttest-SCORE:0.801134+0.0304579\ttest-auc:0.993818+0.00152266\n",
      "[400]\ttrain-SCORE:0.952818+0.0034428\ttrain-auc:0.999106+4.64351e-05\ttest-SCORE:0.808311+0.0248582\ttest-auc:0.993856+0.00151623\n",
      "[500]\ttrain-SCORE:0.957715+0.00388583\ttrain-auc:0.999244+4.20264e-05\ttest-SCORE:0.802253+0.0211957\ttest-auc:0.9939+0.00160269\n",
      "[600]\ttrain-SCORE:0.960326+0.00353013\ttrain-auc:0.999321+4.24604e-05\ttest-SCORE:0.803408+0.0233752\ttest-auc:0.993972+0.00157673\n",
      "[700]\ttrain-SCORE:0.963036+0.00396377\ttrain-auc:0.99937+3.96344e-05\ttest-SCORE:0.801981+0.0249392\ttest-auc:0.993968+0.00158383\n",
      "[800]\ttrain-SCORE:0.964684+0.00328472\ttrain-auc:0.99941+4.69965e-05\ttest-SCORE:0.80339+0.0233115\ttest-auc:0.99398+0.00157859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "649    0.801264\n",
       "Name: test-SCORE-mean, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res = xgbCV(trainFeature,trainLabel,params,10000)\n",
    "cv_res['test-SCORE-mean'][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_fea_test = trans_fea_test.merge(op_fea_test,on='UID',how='outer')\n",
    "testFeature = sample[['UID']].merge(all_fea_test,on='UID',how='left')\n",
    "sub_id = testFeature['UID']\n",
    "testFeature =testFeature.drop('UID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.929966\ttrain-SCORE:0.492539\n",
      "[50]\ttrain-auc:0.988323\ttrain-SCORE:0.77873\n",
      "[100]\ttrain-auc:0.995187\ttrain-SCORE:0.862369\n",
      "[150]\ttrain-auc:0.997445\ttrain-SCORE:0.912762\n",
      "[200]\ttrain-auc:0.998315\ttrain-SCORE:0.930694\n",
      "[250]\ttrain-auc:0.998697\ttrain-SCORE:0.945092\n",
      "[300]\ttrain-auc:0.998933\ttrain-SCORE:0.953469\n",
      "[350]\ttrain-auc:0.999085\ttrain-SCORE:0.958966\n",
      "[400]\ttrain-auc:0.999177\ttrain-SCORE:0.961191\n",
      "[450]\ttrain-auc:0.99926\ttrain-SCORE:0.964202\n",
      "[500]\ttrain-auc:0.999321\ttrain-SCORE:0.965969\n",
      "[550]\ttrain-auc:0.999362\ttrain-SCORE:0.967081\n",
      "[600]\ttrain-auc:0.999392\ttrain-SCORE:0.968521\n",
      "[650]\ttrain-auc:0.999416\ttrain-SCORE:0.969503\n",
      "[699]\ttrain-auc:0.999435\ttrain-SCORE:0.969961\n"
     ]
    }
   ],
   "source": [
    "model,predict = xgbPredict(trainFeature,trainLabel,testFeature,700,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UID</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000</td>\n",
       "      <td>0.035195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30001</td>\n",
       "      <td>0.030558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30002</td>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30003</td>\n",
       "      <td>0.024343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30004</td>\n",
       "      <td>0.000124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     UID       Tag\n",
       "0  30000  0.035195\n",
       "1  30001  0.030558\n",
       "2  30002  0.000580\n",
       "3  30003  0.024343\n",
       "4  30004  0.000124"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['UID'] = sub_id\n",
    "sub['Tag'] = predict\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv(res_path+'baseline.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
