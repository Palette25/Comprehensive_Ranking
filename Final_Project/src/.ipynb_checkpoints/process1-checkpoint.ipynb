{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import warnings\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataPath = '../dataSet/'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(dataPath+'age_train.csv', names=['uid','age'])\n",
    "test = pd.read_csv(dataPath+'age_test.csv', names=['uid'])\n",
    "\n",
    "behavior_info = pd.read_csv(dataPath+'user_behavior_info.csv', \n",
    "                        names=['uid', 'times', 'A', 'B', 'C', 'D', 'E', 'F', 'G'])\n",
    "\n",
    "basic_info = pd.read_csv(dataPath+'user_basic_info.csv', \n",
    "                        names=['uid','gender','city','phone_type','ram','ram_left','rom','rom_left','color','fontSize','ct','carrier','os'])\n",
    "\n",
    "app_package = pd.read_csv(dataPath+'user_app_actived.csv', names=['uid','appid'])\n",
    "app_info = pd.read_csv(dataPath+'app_info.csv', names=['appid','category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For behavior's feature values, do pre-scaling\n",
    "chapters = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "\n",
    "for index in range(len(chapters)):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    # Scaling all behavior features into (0, 1)\n",
    "    behavior_info[chapters[index]] = scaler.fit_transform(behavior_info[chapters[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = ['city', 'phone_type', 'color', 'ct','carrier','os']\n",
    "\n",
    "for index in range(len(chapters)):\n",
    "    labeler = LabelEncoder()\n",
    "    mask = ~basic_info[chapters[index]].isnull()\n",
    "    null_mask = basic_info[chapters[index]].isnull()\n",
    "    basic_info[chapters[index]][mask] = labeler.fit_transform(basic_info[chapters[index]][mask])\n",
    "    basic_info[chapters[index]][null_mask] = 0\n",
    "\n",
    "for index in range(len(chapters)):\n",
    "    basic_info[chapters[index]] = basic_info[chapters[index]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do tfidf-features stacking or not\n",
    "do_stacking = False\n",
    "\n",
    "# app_infos translation\n",
    "def get_str(df):\n",
    "    res = ''\n",
    "    for ele in df.split(\"#\"):\n",
    "        res += ele + ' '\n",
    "    \n",
    "    return res\n",
    "\n",
    "if do_stacking:\n",
    "    app_package['app_str'] = app_package['appid'].apply(lambda x: get_str(x), 1)\n",
    "\n",
    "    # Try Tfidf\n",
    "    tfidf = CountVectorizer()\n",
    "    train_str_app = pd.merge(train[['uid']], app_package[['uid','app_str']], on='uid', how='left')\n",
    "    test_str_app = pd.merge(test[['uid']], app_package[['uid','app_str']], on='uid', how='left')\n",
    "    app_package['app_str'] = tfidf.fit_transform(app_package['app_str'])\n",
    "    train_app = tfidf.transform(list(train_str_app['app_str'])).tocsr()\n",
    "    test_app = tfidf.transform(list(test_str_app['app_str'])).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# According to app_features, do stacking\n",
    "if do_stacking:\n",
    "    train_feature = train_app\n",
    "    test_feature = test_app\n",
    "\n",
    "    df_stack = pd.DataFrame()\n",
    "\n",
    "    all_id = pd.concat([train[['uid']], test[['uid']]])\n",
    "    n_folds = 10\n",
    "    df_stack['uid'] = all_id['uid']\n",
    "\n",
    "    labels = train['age'] - 1\n",
    "\n",
    "    print('LR Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=0, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('LR Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        clf = LogisticRegression(solver='sag', n_jobs=-1, multi_class='multinomial')\n",
    "        clf.fit(train_feature[tr], labels[tr])\n",
    "        score_va = clf.predict(train_feature[va])[:,1]\n",
    "        print(score_va)\n",
    "\n",
    "        score_te = clf.predict(test_feature)[:,1]\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], clf.predict(train_feature[va]))))\n",
    "        stack_train[va, 0] = score_va\n",
    "        stack_test[:, 0] += score_te\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_lr_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    print('SGD Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('SGD Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        sgd = SGDClassifier(loss='log', n_jobs=-1)\n",
    "        sgd.fit(train_feature[tr], labels[tr])\n",
    "        score_va = sgd.predict(train_feature[va])[:,1]\n",
    "        print(score_va)\n",
    "\n",
    "        score_te = sgd.predict(test_feature)[:,1]\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], sgd.predict(train_feature[va]))))\n",
    "        stack_train[va, 0] = score_va\n",
    "        stack_test[:, 0] += score_te\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_sgd_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    print('PAC Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('PAC Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        pac = PassiveAggressiveClassifier(n_jobs=-1)\n",
    "        pac.fit(train_feature[tr], labels[tr])\n",
    "        score_va = pac.predict(train_feature[va])[:,1]\n",
    "\n",
    "        score_te = pac.predict(test_feature)[:,1]\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], pac.predict(train_feature[va]))))\n",
    "        stack_train[va, 0] = score_va\n",
    "        stack_test[:, 0] += score_te\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_pac_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    print('RidgeClassify Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('Ridge Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        ridge = RidgeClassifier(solver='sag')\n",
    "        ridge.fit(train_feature[tr], labels[tr])\n",
    "        score_va = ridge.predict(train_feature[va])[:,1]\n",
    "\n",
    "        score_te = ridge.predict(test_feature)[:,1]\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], ridge.predict(train_feature[va]))))\n",
    "        stack_train[va, 0] = score_va\n",
    "        stack_test[:, 0] += score_te\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_ridge_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    print('BernoulliNB Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('BernoulliNB Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        bnb = BernoulliNB()\n",
    "        bnb.fit(train_feature[tr], labels[tr])\n",
    "        score_va = bnb.predict(train_feature[va])[:,1]\n",
    "\n",
    "        score_te = bnb.predict(test_feature)[:,1]\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], bnb.predict(train_feature[va]))))\n",
    "        stack_train[va, 0] = score_va\n",
    "        stack_test[:, 0] += score_te\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_bnb_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    print('MultinomialNB Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('MultinomialNB Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        mnb = MultinomialNB()\n",
    "        mnb.fit(train_feature[tr], labels[tr])\n",
    "        score_va = mnb.predict(train_feature[va])[:,1]\n",
    "\n",
    "        score_te = mnb.predict(test_feature)[:,1]\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], mnb.predict(train_feature[va]))))\n",
    "        stack_train[va, 0] = score_va\n",
    "        stack_test[:, 0] += score_te\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_mnb_classify_{}'.format('age')] = stack[:, 0]\n",
    "    \n",
    "    print('LinearSVC Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('LinearSVC Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        lsvc = LinearSVC()\n",
    "        lsvc.fit(train_feature[tr], labels[tr])\n",
    "        score_va = lsvc._predict(train_feature[va])[:,1]\n",
    "\n",
    "        score_te = lsvc._predict(test_feature)[:,1]\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], lsvc.predict(train_feature[va]))))\n",
    "        stack_train[va, 0] = score_va\n",
    "        stack_test[:, 0] += score_te\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_lsvc_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    df_stack.to_csv(dataPath+'tfidf_classfiy.csv', index=None, encoding='utf8')\n",
    "    print('Tfidf Features Stacking is Done~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate user's activated apps number\n",
    "do_get_length = False\n",
    "\n",
    "def get_app_len(df):\n",
    "    return len(df.split('#'))\n",
    "\n",
    "if do_get_length:\n",
    "    app_number_feat = pd.DataFrame(columns=['uid', 'app_number'])\n",
    "    app_number_feat['uid'] = app_package['uid']\n",
    "    app_number_feat['app_number'] = app_package['appid'].apply(lambda x: get_app_len(x), 1)\n",
    "\n",
    "    app_number_feat.to_csv(dataPath + 'app_activated_sum.csv', index=False)\n",
    "else:\n",
    "    app_number_feat = pd.read_csv(dataPath+'app_activated_sum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "do_lda = False\n",
    "\n",
    "if do_lda:\n",
    "    apps = app_package['appid'].apply(lambda x: get_str(x), 1)\n",
    "    vectorizer = CountVectorizer()\n",
    "    cntTf = vectorizer.fit_transform(apps)\n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_topics=10)\n",
    "    docres = lda.fit_transform(cntTf)\n",
    "    lda_feat = pd.DataFrame(docres)\n",
    "    \n",
    "    lda_feat.to_csv(dataPath + 'lda_feat.csv', index=False)\n",
    "else:\n",
    "    lda_feat = pd.read_csv(dataPath+'lda_feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'uid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-0c3224919193>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtrainData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbehavior_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mtrainData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf_feat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtrainData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapp_package\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mtrainData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapp_number_feat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mtrainLabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     45\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                          validate=validate)\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    527\u001b[0m         (self.left_join_keys,\n\u001b[0;32m    528\u001b[0m          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                             right_keys.append(\n\u001b[1;32m--> 833\u001b[1;33m                                 right._get_label_or_level_values(rk))\n\u001b[0m\u001b[0;32m    834\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1704\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1705\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1706\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1708\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'uid'"
     ]
    }
   ],
   "source": [
    "tfidf_feat = pd.read_csv(dataPath+'tfidf_classfiy.csv')\n",
    "\n",
    "packages = app_package\n",
    "\n",
    "# Merge applist lda\n",
    "packages = pd.concat([packages, lda_feat], axis=1)\n",
    "packages = packages.drop('app_str', axis=1)\n",
    "packages = packages.drop('appid', axis=1)\n",
    "\n",
    "# Combine all trainData features\n",
    "trainData = pd.merge(train, basic_info, on='uid', how='left')\n",
    "trainData = pd.merge(trainData, behavior_info, on='uid', how='left')\n",
    "trainData = pd.merge(trainData, tfidf_feat, on='uid', how='left')\n",
    "trainData = pd.merge(trainData, app_package, on='uid', how='left')\n",
    "trainData = pd.merge(trainData, app_number_feat, on='uid', how='left')\n",
    "trainLabel = trainData['age'] - 1\n",
    "\n",
    "# Delete with NaN values\n",
    "for col in trainData.columns:\n",
    "    mask = trainData[col].isnull()\n",
    "    trainData[col][mask] = 0\n",
    "\n",
    "feature_signs = [x for x in trainData.columns if x not in ['uid', 'age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 1.02824\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-99fef976ec52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     model = lgb.train(params, trainDataSet, num_boost_round=5000,\n\u001b[1;32m---> 21\u001b[1;33m                       valid_sets=testDataSet, verbose_eval=100, early_stopping_rounds=200)\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1802\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Establish lightGBM to check K-Fold score\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.08,\n",
    "    'num_class': 6,\n",
    "    'nthread': 8\n",
    "}\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "for index, (trainIndex, testIndex) in enumerate(kfold.split(trainData, trainLabel)):\n",
    "    tr_x = trainData[feature_signs].reindex(index=trainIndex, copy=False)\n",
    "    tr_y = trainLabel[trainIndex]\n",
    "    te_x = trainData[feature_signs].reindex(index=testIndex, copy=False)\n",
    "    te_y = trainLabel[testIndex]\n",
    "    \n",
    "    trainDataSet = lgb.Dataset(tr_x, label=tr_y)\n",
    "    testDataSet = lgb.Dataset(te_x, label=te_y)\n",
    "    \n",
    "    model = lgb.train(params, trainDataSet, num_boost_round=5000,\n",
    "                      valid_sets=testDataSet, verbose_eval=100, early_stopping_rounds=200)\n",
    "    \n",
    "    prediction = model.predict(te_x, num_iteration=model.best_iteration)\n",
    "    \n",
    "    # Deal with float vals in prediction\n",
    "    pred = []\n",
    "    for ele in prediction:\n",
    "        pred.append(ele.tolist().index(max(ele)) + 1)\n",
    "    \n",
    "    accuracy = accuracy_score(te_y+1, pred)\n",
    "    loss = mean_squared_error(te_y+1, pred)\n",
    "    \n",
    "    print('KFold Iteration: %d' % index)\n",
    "    print('Accuracy: %.5f' % accuracy)\n",
    "    print('Loss: %.5f' % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish lightGBM to check K-Fold score\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.08,\n",
    "    'num_class': 6,\n",
    "    'nthread': 8\n",
    "}\n",
    "\n",
    "# Finally create lightGBM model to predict test labels\n",
    "# Combine all trainData features\n",
    "testData = pd.merge(test, basic_info, on='uid', how='left')\n",
    "testData = pd.merge(testData, behavior_info, on='uid', how='left')\n",
    "testData = pd.merge(testData, tfidf_feat, on='uid', how='left')\n",
    "testData = pd.merge(testData, app_package, on='uid', how='left')\n",
    "testData = pd.merge(testData, app_number_feat, on='uid', how='left')\n",
    "\n",
    "# Delete with NaN values\n",
    "for col in testData.columns:\n",
    "    mask = testData[col].isnull()\n",
    "    testData[col][mask] = 0\n",
    "    \n",
    "tr_x = trainData[feature_signs]\n",
    "tr_y = trainLabel\n",
    "te_x = testData[feature_signs]\n",
    "\n",
    "trainDataSet = lgb.Dataset(tr_x, label=tr_y)\n",
    "testDataSet = lgb.Dataset(tr_x, label=tr_y)\n",
    "\n",
    "model = lgb.train(params, trainDataSet, num_boost_round=5000,\n",
    "                      valid_sets=testDataSet, verbose_eval=100, early_stopping_rounds=200)\n",
    "    \n",
    "prediction = model.predict(te_x, num_iteration=model.best_iteration)\n",
    "\n",
    "# Deal with float vals in prediction\n",
    "pred = []\n",
    "for ele in prediction:\n",
    "    pred.append(ele.tolist().index(max(ele)) + 1)\n",
    "\n",
    "test['age'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('../result/submission.csv', header=['id', 'label'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
