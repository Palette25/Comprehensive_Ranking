{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import warnings\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataPath = '../dataSet/'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(dataPath+'age_train.csv', names=['uid','age'])\n",
    "test = pd.read_csv(dataPath+'age_test.csv', names=['uid'])\n",
    "\n",
    "behavior_info = pd.read_csv(dataPath+'user_behavior_info.csv', \n",
    "                        names=['uid', 'times', 'A', 'B', 'C', 'D', 'E', 'F', 'G'])\n",
    "\n",
    "basic_info = pd.read_csv(dataPath+'user_basic_info.csv', \n",
    "                        names=['uid','gender','city','phone_type','ram','ram_left','rom','rom_left','color','fontSize','ct','carrier','os'])\n",
    "\n",
    "app_package = pd.read_csv(dataPath+'user_app_actived.csv', names=['uid','appid'])\n",
    "app_info = pd.read_csv(dataPath+'app_info.csv', names=['appid','category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For behavior's feature values, do pre-scaling\n",
    "chapters = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "\n",
    "for index in range(len(chapters)):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    # Scaling all behavior features into (0, 1)\n",
    "    behavior_info[chapters[index]] = scaler.fit_transform(behavior_info[chapters[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters = ['city', 'phone_type', 'color', 'ct','carrier','os']\n",
    "\n",
    "for index in range(len(chapters)):\n",
    "    labeler = LabelEncoder()\n",
    "    mask = ~basic_info[chapters[index]].isnull()\n",
    "    null_mask = basic_info[chapters[index]].isnull()\n",
    "    basic_info[chapters[index]][mask] = labeler.fit_transform(basic_info[chapters[index]][mask])\n",
    "    basic_info[chapters[index]][null_mask] = 0\n",
    "\n",
    "for index in range(len(chapters)):\n",
    "    basic_info[chapters[index]] = basic_info[chapters[index]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do tfidf-features stacking or not\n",
    "do_stacking = False\n",
    "\n",
    "# app_infos translation\n",
    "def get_str(df):\n",
    "    res = ''\n",
    "    for ele in df.split(\"#\"):\n",
    "        res += ele + ' '\n",
    "    \n",
    "    return res\n",
    "\n",
    "if do_stacking:\n",
    "    app_package['app_str'] = app_package['appid'].apply(lambda x: get_str(x), 1)\n",
    "\n",
    "    # Try Tfidf\n",
    "    tfidf = CountVectorizer()\n",
    "    train_str_app = pd.merge(train[['uid']], app_package[['uid','app_str']], on='uid', how='left')\n",
    "    test_str_app = pd.merge(test[['uid']], app_package[['uid','app_str']], on='uid', how='left')\n",
    "    app_package['app_str'] = tfidf.fit_transform(app_package['app_str'])\n",
    "    train_app = tfidf.transform(list(train_str_app['app_str'])).tocsr()\n",
    "    test_app = tfidf.transform(list(test_str_app['app_str'])).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# According to app_features, do stacking\n",
    "if do_stacking:\n",
    "    train_feature = train_app\n",
    "    test_feature = test_app\n",
    "\n",
    "    df_stack = pd.DataFrame()\n",
    "\n",
    "    all_id = pd.concat([train[['uid']], test[['uid']]])\n",
    "    n_folds = 10\n",
    "    df_stack['uid'] = all_id['uid']\n",
    "\n",
    "    labels = train['age'] - 1\n",
    "\n",
    "    print('LR Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=0, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('LR Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        clf = LogisticRegression(solver='sag', n_jobs=-1, multi_class='multinomial')\n",
    "        clf.fit(train_feature[tr], labels[tr])\n",
    "        score_va = clf.predict(train_feature[va])[:,1]\n",
    "        print(score_va)\n",
    "\n",
    "        score_te = clf.predict(test_feature)[:,1]\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], clf.predict(train_feature[va]))))\n",
    "        stack_train[va, 0] = score_va\n",
    "        stack_test[:, 0] += score_te\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_lr_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    print('SGD Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('SGD Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        sgd = SGDClassifier(loss='log', n_jobs=-1)\n",
    "        sgd.fit(train_feature[tr], labels[tr])\n",
    "        score_va = sgd.predict(train_feature[va])[:,1]\n",
    "        print(score_va)\n",
    "\n",
    "        score_te = sgd.predict(test_feature)[:,1]\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], sgd.predict(train_feature[va]))))\n",
    "        stack_train[va, 0] = score_va\n",
    "        stack_test[:, 0] += score_te\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_sgd_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    print('PAC Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('PAC Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        pac = PassiveAggressiveClassifier(n_jobs=-1)\n",
    "        pac.fit(train_feature[tr], labels[tr])\n",
    "        score_va = pac.predict(train_feature[va])[:,1]\n",
    "\n",
    "        score_te = pac.predict(test_feature)[:,1]\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], pac.predict(train_feature[va]))))\n",
    "        stack_train[va, 0] = score_va\n",
    "        stack_test[:, 0] += score_te\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_pac_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    print('RidgeClassify Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('Ridge Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        ridge = RidgeClassifier(solver='sag')\n",
    "        ridge.fit(train_feature[tr], labels[tr])\n",
    "        score_va = ridge.predict(train_feature[va])[:,1]\n",
    "\n",
    "        score_te = ridge.predict(test_feature)[:,1]\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], ridge.predict(train_feature[va]))))\n",
    "        stack_train[va, 0] = score_va\n",
    "        stack_test[:, 0] += score_te\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_ridge_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    print('BernoulliNB Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('BernoulliNB Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        bnb = BernoulliNB()\n",
    "        bnb.fit(train_feature[tr], labels[tr])\n",
    "        score_va = bnb.predict(train_feature[va])[:,1]\n",
    "\n",
    "        score_te = bnb.predict(test_feature)[:,1]\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], bnb.predict(train_feature[va]))))\n",
    "        stack_train[va, 0] = score_va\n",
    "        stack_test[:, 0] += score_te\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_bnb_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    print('MultinomialNB Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('MultinomialNB Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        mnb = MultinomialNB()\n",
    "        mnb.fit(train_feature[tr], labels[tr])\n",
    "        score_va = mnb.predict(train_feature[va])[:,1]\n",
    "\n",
    "        score_te = mnb.predict(test_feature)[:,1]\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], mnb.predict(train_feature[va]))))\n",
    "        stack_train[va, 0] = score_va\n",
    "        stack_test[:, 0] += score_te\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_mnb_classify_{}'.format('age')] = stack[:, 0]\n",
    "    \n",
    "    print('LinearSVC Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('LinearSVC Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        lsvc = LinearSVC()\n",
    "        lsvc.fit(train_feature[tr], labels[tr])\n",
    "        score_va = lsvc._predict(train_feature[va])[:,1]\n",
    "\n",
    "        score_te = lsvc._predict(test_feature)[:,1]\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], lsvc.predict(train_feature[va]))))\n",
    "        stack_train[va, 0] = score_va\n",
    "        stack_test[:, 0] += score_te\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_lsvc_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    df_stack.to_csv(dataPath+'tfidf_classfiy.csv', index=None, encoding='utf8')\n",
    "    print('Tfidf Features Stacking is Done~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate user's activated apps number\n",
    "do_get_length = False\n",
    "\n",
    "def get_app_len(df):\n",
    "    return len(df.split('#'))\n",
    "\n",
    "if do_get_length:\n",
    "    app_number_feat = pd.DataFrame(columns=['uid', 'app_number'])\n",
    "    app_number_feat['uid'] = app_package['uid']\n",
    "    app_number_feat['app_number'] = app_package['appid'].apply(lambda x: get_app_len(x), 1)\n",
    "\n",
    "    app_number_feat.to_csv(dataPath + 'app_activated_sum.csv', index=False)\n",
    "else:\n",
    "    app_number_feat = pd.read_csv(dataPath+'app_activated_sum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "do_lda = False\n",
    "\n",
    "if do_lda:\n",
    "    apps = app_package['appid'].apply(lambda x: get_str(x), 1)\n",
    "    vectorizer = CountVectorizer()\n",
    "    cntTf = vectorizer.fit_transform(apps)\n",
    "    \n",
    "    lda = LatentDirichletAllocation(n_topics=10)\n",
    "    docres = lda.fit_transform(cntTf)\n",
    "    lda_feat = pd.DataFrame(docres)\n",
    "    \n",
    "    lda_feat.to_csv(dataPath + 'lda_feat.csv', index=False)\n",
    "else:\n",
    "    lda_feat = pd.read_csv(dataPath+'lda_feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_feat = pd.read_csv(dataPath+'tfidf_classfiy.csv')\n",
    "\n",
    "packages = app_package\n",
    "\n",
    "# Merge applist lda\n",
    "packages = pd.concat([packages, lda_feat], axis=1)\n",
    "packages = packages.drop('appid', axis=1)\n",
    "\n",
    "# Combine all trainData features\n",
    "trainData = pd.merge(train, basic_info, on='uid', how='left')\n",
    "trainData = pd.merge(trainData, behavior_info, on='uid', how='left')\n",
    "trainData = pd.merge(trainData, tfidf_feat, on='uid', how='left')\n",
    "trainData = pd.merge(trainData, packages, on='uid', how='left')\n",
    "#trainData = pd.merge(trainData, app_number_feat, on='uid', how='left')\n",
    "trainLabel = trainData['age'] - 1\n",
    "\n",
    "# Delete with NaN values\n",
    "for col in trainData.columns:\n",
    "    mask = trainData[col].isnull()\n",
    "    trainData[col][mask] = 0\n",
    "\n",
    "feature_signs = [x for x in trainData.columns if x not in ['uid', 'age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    }
   ],
   "source": [
    "# Establish lightGBM to check K-Fold score\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.08,\n",
    "    'num_class': 6,\n",
    "    'nthread': 8\n",
    "}\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "for index, (trainIndex, testIndex) in enumerate(kfold.split(trainData, trainLabel)):\n",
    "    tr_x = trainData[feature_signs].reindex(index=trainIndex, copy=False)\n",
    "    tr_y = trainLabel[trainIndex]\n",
    "    te_x = trainData[feature_signs].reindex(index=testIndex, copy=False)\n",
    "    te_y = trainLabel[testIndex]\n",
    "    \n",
    "    trainDataSet = lgb.Dataset(tr_x, label=tr_y)\n",
    "    testDataSet = lgb.Dataset(te_x, label=te_y)\n",
    "    \n",
    "    model = lgb.train(params, trainDataSet, num_boost_round=5000,\n",
    "                      valid_sets=testDataSet, verbose_eval=100, early_stopping_rounds=200)\n",
    "    \n",
    "    prediction = model.predict(te_x, num_iteration=model.best_iteration)\n",
    "    \n",
    "    # Deal with float vals in prediction\n",
    "    pred = []\n",
    "    for ele in prediction:\n",
    "        pred.append(ele.tolist().index(max(ele)) + 1)\n",
    "    \n",
    "    accuracy = accuracy_score(te_y+1, pred)\n",
    "    loss = mean_squared_error(te_y+1, pred)\n",
    "    \n",
    "    print('KFold Iteration: %d' % index)\n",
    "    print('Accuracy: %.5f' % accuracy)\n",
    "    print('Loss: %.5f' % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish lightGBM to check K-Fold score\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.08,\n",
    "    'num_class': 6,\n",
    "    'nthread': 8\n",
    "}\n",
    "\n",
    "# Finally create lightGBM model to predict test labels\n",
    "# Combine all trainData features\n",
    "testData = pd.merge(test, basic_info, on='uid', how='left')\n",
    "testData = pd.merge(testData, behavior_info, on='uid', how='left')\n",
    "testData = pd.merge(testData, tfidf_feat, on='uid', how='left')\n",
    "testData = pd.merge(testData, app_package, on='uid', how='left')\n",
    "testData = pd.merge(testData, app_number_feat, on='uid', how='left')\n",
    "\n",
    "# Delete with NaN values\n",
    "for col in testData.columns:\n",
    "    mask = testData[col].isnull()\n",
    "    testData[col][mask] = 0\n",
    "    \n",
    "tr_x = trainData[feature_signs]\n",
    "tr_y = trainLabel\n",
    "te_x = testData[feature_signs]\n",
    "\n",
    "trainDataSet = lgb.Dataset(tr_x, label=tr_y)\n",
    "testDataSet = lgb.Dataset(tr_x, label=tr_y)\n",
    "\n",
    "model = lgb.train(params, trainDataSet, num_boost_round=5000,\n",
    "                      valid_sets=testDataSet, verbose_eval=100, early_stopping_rounds=200)\n",
    "    \n",
    "prediction = model.predict(te_x, num_iteration=model.best_iteration)\n",
    "\n",
    "# Deal with float vals in prediction\n",
    "pred = []\n",
    "for ele in prediction:\n",
    "    pred.append(ele.tolist().index(max(ele)) + 1)\n",
    "\n",
    "test['age'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('../result/submission.csv', header=['id', 'label'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
