{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import warnings\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataPath = '../dataSet/'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(dataPath+'age_train.csv', names=['uid','age'])\n",
    "test = pd.read_csv(dataPath+'age_test.csv', names=['uid'])\n",
    "\n",
    "app_package = pd.read_csv(dataPath+'user_app_actived.csv', names=['uid','appid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do tfidf-features stacking or not\n",
    "do_stacking = True\n",
    "\n",
    "# app_infos translation\n",
    "def get_str(df):\n",
    "    res = ''\n",
    "    for ele in df.split(\"#\"):\n",
    "        res += ele + ' '\n",
    "    \n",
    "    return res\n",
    "\n",
    "if do_stacking:\n",
    "    app_package['app_str'] = app_package['appid'].apply(lambda x: get_str(x), 1)\n",
    "\n",
    "    # Try Tfidf\n",
    "    tfidf = CountVectorizer()\n",
    "    train_str_app = pd.merge(train[['uid']], app_package[['uid','app_str']], on='uid', how='left')\n",
    "    test_str_app = pd.merge(test[['uid']], app_package[['uid','app_str']], on='uid', how='left')\n",
    "    app_package['app_str'] = tfidf.fit_transform(app_package['app_str'])\n",
    "    train_app = tfidf.transform(list(train_str_app['app_str'])).tocsc()\n",
    "    test_app = tfidf.transform(list(test_str_app['app_str'])).tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = train_app.tocsc()\n",
    "testData = test_app.tocsc()\n",
    "\n",
    "trainLabel = train['age'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "do_stacking = False\n",
    "\n",
    "# According to app_features, do stacking\n",
    "if do_stacking:\n",
    "    train_feature = train_app\n",
    "    test_feature = test_app\n",
    "\n",
    "    df_stack = pd.DataFrame()\n",
    "\n",
    "    all_id = pd.concat([train[['uid']], test[['uid']]])\n",
    "    n_folds = 10\n",
    "    df_stack['uid'] = all_id['uid']\n",
    "\n",
    "    labels = train['age'] - 1\n",
    "\n",
    "    print('LR Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=0, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('LR Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        clf = LogisticRegression(solver='sag', n_jobs=-1)\n",
    "        clf.fit(train_feature[tr], labels[tr])\n",
    "        score_va = clf.predict(train_feature[va])\n",
    "\n",
    "        score_te = clf.predict(test_feature)\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], score_va)))\n",
    "        print('Accuracy: ' + str(accuracy_score(labels[va], score_va)))\n",
    "        \n",
    "        stack_train[va, 0] = score_va + 1\n",
    "        stack_test[:, 0] += score_te + 1\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_lr_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    print('SGD Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('SGD Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        sgd = SGDClassifier(loss='log', n_jobs=-1)\n",
    "        sgd.fit(train_feature[tr], labels[tr])\n",
    "        score_va = sgd.predict(train_feature[va])\n",
    "\n",
    "        score_te = sgd.predict(test_feature)\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], sgd.predict(train_feature[va]))))\n",
    "        print('Accuracy: ' + str(accuracy_score(labels[va], score_va)))\n",
    "        \n",
    "        stack_train[va, 0] = score_va + 1\n",
    "        stack_test[:, 0] += score_te + 1\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_sgd_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    print('PAC Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('PAC Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        pac = PassiveAggressiveClassifier(n_jobs=-1)\n",
    "        pac.fit(train_feature[tr], labels[tr])\n",
    "        score_va = pac.predict(train_feature[va])\n",
    "\n",
    "        score_te = pac.predict(test_feature)\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], pac.predict(train_feature[va]))))\n",
    "        print('Accuracy: ' + str(accuracy_score(labels[va], score_va)))\n",
    "        \n",
    "        stack_train[va, 0] = score_va + 1\n",
    "        stack_test[:, 0] += score_te + 1\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_pac_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    df_stack.to_csv(dataPath+'tfidf_classfiy.csv', index=None, encoding='utf8')\n",
    "    print('Tfidf Features Stacking is Done~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 1.09982\n",
      "[200]\tvalid_0's multi_logloss: 1.03429\n",
      "[300]\tvalid_0's multi_logloss: 1.00634\n",
      "[400]\tvalid_0's multi_logloss: 0.990361\n",
      "[500]\tvalid_0's multi_logloss: 0.980393\n",
      "[600]\tvalid_0's multi_logloss: 0.973435\n",
      "[700]\tvalid_0's multi_logloss: 0.968951\n",
      "[800]\tvalid_0's multi_logloss: 0.965688\n",
      "[900]\tvalid_0's multi_logloss: 0.962811\n",
      "[1000]\tvalid_0's multi_logloss: 0.961687\n",
      "[1100]\tvalid_0's multi_logloss: 0.959958\n",
      "[1200]\tvalid_0's multi_logloss: 0.958694\n",
      "[1300]\tvalid_0's multi_logloss: 0.958179\n",
      "[1400]\tvalid_0's multi_logloss: 0.957703\n",
      "[1500]\tvalid_0's multi_logloss: 0.957484\n",
      "[1600]\tvalid_0's multi_logloss: 0.956704\n",
      "[1700]\tvalid_0's multi_logloss: 0.959005\n",
      "Early stopping, best iteration is:\n",
      "[1619]\tvalid_0's multi_logloss: 0.956558\n",
      "KFold Iteration: 0\n",
      "Accuracy: 0.60375\n",
      "Loss: 0.74542\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 1.09969\n",
      "[200]\tvalid_0's multi_logloss: 1.03447\n",
      "[300]\tvalid_0's multi_logloss: 1.00641\n",
      "[400]\tvalid_0's multi_logloss: 0.990534\n",
      "[500]\tvalid_0's multi_logloss: 0.980604\n",
      "[600]\tvalid_0's multi_logloss: 0.973435\n",
      "[700]\tvalid_0's multi_logloss: 0.968308\n",
      "[800]\tvalid_0's multi_logloss: 0.96444\n",
      "[900]\tvalid_0's multi_logloss: 0.961657\n",
      "[1000]\tvalid_0's multi_logloss: 0.960612\n",
      "[1100]\tvalid_0's multi_logloss: 0.958838\n",
      "[1200]\tvalid_0's multi_logloss: 0.957437\n",
      "[1300]\tvalid_0's multi_logloss: 0.956275\n",
      "[1400]\tvalid_0's multi_logloss: 0.955323\n",
      "[1500]\tvalid_0's multi_logloss: 0.954527\n",
      "[1600]\tvalid_0's multi_logloss: 0.953779\n",
      "[1700]\tvalid_0's multi_logloss: 0.953139\n",
      "[1800]\tvalid_0's multi_logloss: 0.952653\n",
      "[1900]\tvalid_0's multi_logloss: 0.952421\n",
      "[2000]\tvalid_0's multi_logloss: 0.951907\n",
      "[2100]\tvalid_0's multi_logloss: 0.951452\n",
      "[2200]\tvalid_0's multi_logloss: 0.951015\n",
      "[2300]\tvalid_0's multi_logloss: 0.950673\n",
      "[2400]\tvalid_0's multi_logloss: 0.950359\n",
      "[2500]\tvalid_0's multi_logloss: 0.950071\n",
      "[2600]\tvalid_0's multi_logloss: 0.94995\n",
      "[2700]\tvalid_0's multi_logloss: 0.949638\n",
      "[2800]\tvalid_0's multi_logloss: 0.949342\n",
      "[2900]\tvalid_0's multi_logloss: 0.949082\n",
      "[3000]\tvalid_0's multi_logloss: 0.948872\n",
      "[3100]\tvalid_0's multi_logloss: 0.948832\n",
      "Early stopping, best iteration is:\n",
      "[3026]\tvalid_0's multi_logloss: 0.948774\n",
      "KFold Iteration: 1\n",
      "Accuracy: 0.60585\n",
      "Loss: 0.74337\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 1.10203\n",
      "[200]\tvalid_0's multi_logloss: 1.03705\n",
      "[300]\tvalid_0's multi_logloss: 1.00913\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2de9964fd32d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     model = lgb.train(params, trainDataSet, num_boost_round=5000,\n\u001b[1;32m---> 21\u001b[1;33m                       valid_sets=testDataSet, verbose_eval=100, early_stopping_rounds=100)\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1802\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Establish lightGBM to check K-Fold score\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.08,\n",
    "    'num_class': 6,\n",
    "    'nthread': 8\n",
    "}\n",
    "\n",
    "do_KFold = False\n",
    "\n",
    "if do_KFold:\n",
    "    kfold = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "    for index, (trainIndex, testIndex) in enumerate(kfold.split(trainData, trainLabel)):\n",
    "        tr_x = trainData[trainIndex].astype(float)\n",
    "        tr_y = trainLabel[trainIndex].astype(float)\n",
    "        te_x = trainData[testIndex].astype(float)\n",
    "        te_y = trainLabel[testIndex].astype(float)\n",
    "\n",
    "        trainDataSet = lgb.Dataset(tr_x, label=tr_y)\n",
    "        testDataSet = lgb.Dataset(te_x, label=te_y)\n",
    "\n",
    "        model = lgb.train(params, trainDataSet, num_boost_round=5000,\n",
    "                          valid_sets=testDataSet, verbose_eval=100, early_stopping_rounds=100)\n",
    "\n",
    "        prediction = model.predict(te_x, num_iteration=model.best_iteration)\n",
    "\n",
    "        # Deal with float vals in prediction\n",
    "        pred = []\n",
    "        for ele in prediction:\n",
    "            pred.append(ele.tolist().index(max(ele)) + 1)\n",
    "\n",
    "        accuracy = accuracy_score(te_y+1, pred)\n",
    "        loss = mean_squared_error(te_y+1, pred)\n",
    "\n",
    "        print('KFold Iteration: %d' % index)\n",
    "        print('Accuracy: %.5f' % accuracy)\n",
    "        print('Loss: %.5f' % loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-af46cae5099b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m model = lgb.train(params, trainDataSet, num_boost_round=5000,\n\u001b[1;32m---> 17\u001b[1;33m                       valid_sets=testDataSet, verbose_eval=100, early_stopping_rounds=100)\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python35\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1802\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.10,\n",
    "    'num_class': 6,\n",
    "    'nthread': 8\n",
    "}\n",
    "\n",
    "tr_x = trainData.astype(float)\n",
    "tr_y = trainLabel.astype(float)\n",
    "te_x = testData.astype(float)\n",
    "\n",
    "trainDataSet = lgb.Dataset(tr_x, label=tr_y)\n",
    "testDataSet = lgb.Dataset(tr_x, label=tr_y)\n",
    "\n",
    "model = lgb.train(params, trainDataSet, num_boost_round=5000,\n",
    "                      valid_sets=testDataSet, verbose_eval=100, early_stopping_rounds=100)\n",
    "    \n",
    "prediction = model.predict(te_x, num_iteration=model.best_iteration)\n",
    "\n",
    "# Deal with float vals in prediction\n",
    "pred = []\n",
    "for ele in prediction:\n",
    "    pred.append(ele.tolist().index(max(ele)) + 1)\n",
    "\n",
    "test['age'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('../result/submission_tfidf.csv', header=['id', 'label'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
