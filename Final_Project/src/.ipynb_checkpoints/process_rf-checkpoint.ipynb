{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python35\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import warnings\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "dataPath = '../dataSet/'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(dataPath+'age_train.csv', names=['uid','age'])\n",
    "test = pd.read_csv(dataPath+'age_test.csv', names=['uid'])\n",
    "\n",
    "app_package = pd.read_csv(dataPath+'user_app_actived.csv', names=['uid','appid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_number_feat = pd.read_csv(dataPath+'app_activated_sum.csv')\n",
    "\n",
    "train = pd.merge(train, app_package, on='uid', how='left')\n",
    "train = pd.merge(train, app_number_feat, on='uid', how='left')\n",
    "test = pd.merge(test, app_package, on='uid', how='left')\n",
    "test = pd.merge(test, app_number_feat, on='uid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText, Word2Vec\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "# Perform Word to Vec embedding\n",
    "do_embedding = False\n",
    "do_fast_model = False\n",
    "embedding_size = 128\n",
    "\n",
    "if do_fast_model:\n",
    "    fast_model = Word2Vec(list(app_package['app_list']), size=embedding_size, window=4, min_count=3, negative=2,\n",
    "                         sg=1, sample=0.002, hs=1, workers=8)\n",
    "    fast_model.save(dataPath + 'nn/fastmodel.model')\n",
    "else:\n",
    "    fast_model = Word2Vec.load(dataPath + 'nn/fastmodel.model')\n",
    "    \n",
    "if do_embedding:\n",
    "    embedding_fast = pd.DataFrame([fast_model[word] for word in (fast_model.wv.vocab)])\n",
    "    embedding_fast['app'] = list(fast_model.wv.vocab)\n",
    "    embedding_fast.columns = ['fast_dim_%s' % str(i) for i in range(embedding_size)] + ['app']\n",
    "    embedding_fast.to_csv(dataPath + 'embedding_fast.csv')\n",
    "else:\n",
    "    embedding_fast = pd.read_csv(dataPath + 'embedding_fast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower=False, char_level=False, split='#')\n",
    "tokenizer.fit_on_texts(list(app_package['appid']))\n",
    "\n",
    "X_seq = tokenizer.texts_to_sequences(train['appid'])\n",
    "X_test_seq = tokenizer.texts_to_sequences(test['appid'])\n",
    "\n",
    "X = pad_sequences(X_seq, maxlen=100, value=0)\n",
    "X_test = pad_sequences(X_test_seq, maxlen=100, value=0)\n",
    "\n",
    "max_features = 30000\n",
    "embedding_matrix = np.zeros((max_features, embedding_size))\n",
    "for word in tokenizer.word_index:\n",
    "    if word not in fast_model.wv.vocab:\n",
    "        continue\n",
    "    embedding_matrix[tokenizer.word_index[word]] = fast_model[word]\n",
    "\n",
    "embedding_pd = pd.DataFrame(embedding_matrix)\n",
    "embedding_pd.to_csv(dataPath + 'embedding_matrix.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_age = train['age']\n",
    "\n",
    "sub = np.zeros((X_test.shape[0], ))\n",
    "oof_pref = np.zeros((X.shape[0], ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_age = train['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\n",
    "for index, (trainIndex, testIndex) in enumerate(kfold.split(X, Y_age)):\n",
    "    tr_x = X[trainIndex]\n",
    "    tr_y = Y_age[trainIndex]\n",
    "    te_x = X[testIndex]\n",
    "    te_y = Y_age[testIndex]\n",
    "    \n",
    "    model = lgb.LGBMClassifier(nthread=8, feature_fraction=0.4, bagging_fraction=0.632,\n",
    "                               bagging_freq=10, n_estimators=1500)\n",
    "    model.fit(tr_x, tr_y)\n",
    "    \n",
    "    prediction = model.predict(te_x)\n",
    "    # Deal with float vals in prediction\n",
    "    pred = prediction\n",
    "    \n",
    "    accuracy = accuracy_score(te_y, pred)\n",
    "    loss = mean_squared_error(te_y, pred)\n",
    "    \n",
    "    train_prediction = model.predict(tr_x)\n",
    "    train_accuracy = accuracy_score(tr_y, train_prediction)\n",
    "    train_loss = mean_squared_error(tr_y, train_prediction)\n",
    "    \n",
    "    oof_pref[testIndex] = pred\n",
    "    \n",
    "    print('KFold Iteration: %d' % index)\n",
    "    print('Train Accuracy: %.5f, Train Loss: %.5f' % (train_accuracy, train_loss))\n",
    "    print('Validation Accuracy: %.5f, Validation Loss: %.5f' % (accuracy, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(nthread=8, feature_fraction=0.4, bagging_fraction=0.632,\n",
    "                               bagging_freq=10, n_estimators=1500)\n",
    "model.fit(X, Y_age)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "final_sub = test[['uid']]\n",
    "final_sub.columns = ['uid', 'age']\n",
    "final_sub['age'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sub.to_csv('../result/submission.csv', header=['id', 'label'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
