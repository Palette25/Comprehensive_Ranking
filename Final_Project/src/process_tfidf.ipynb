{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import warnings\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "dataPath = '../dataSet/'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(dataPath+'age_train.csv', names=['uid','age'])\n",
    "test = pd.read_csv(dataPath+'age_test.csv', names=['uid'])\n",
    "\n",
    "app_package = pd.read_csv(dataPath+'user_app_actived.csv', names=['uid','appid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do tfidf-features stacking or not\n",
    "do_stacking = True\n",
    "\n",
    "# app_infos translation\n",
    "def get_str(df):\n",
    "    res = ''\n",
    "    for ele in df.split(\"#\"):\n",
    "        res += ele + ' '\n",
    "    \n",
    "    return res\n",
    "\n",
    "if do_stacking:\n",
    "    app_package['app_str'] = app_package['appid'].apply(lambda x: get_str(x), 1)\n",
    "\n",
    "    # Try Tfidf\n",
    "    tfidf = CountVectorizer()\n",
    "    train_str_app = pd.merge(train[['uid']], app_package[['uid','app_str']], on='uid', how='left')\n",
    "    test_str_app = pd.merge(test[['uid']], app_package[['uid','app_str']], on='uid', how='left')\n",
    "    app_package['app_str'] = tfidf.fit_transform(app_package['app_str'])\n",
    "    train_app = tfidf.transform(list(train_str_app['app_str'])).tocsc()\n",
    "    test_app = tfidf.transform(list(test_str_app['app_str'])).tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = train_app.tocsc()\n",
    "testData = test_app.tocsc()\n",
    "\n",
    "trainLabel = train['age'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "do_stacking = False\n",
    "\n",
    "# According to app_features, do stacking\n",
    "if do_stacking:\n",
    "    train_feature = train_app\n",
    "    test_feature = test_app\n",
    "\n",
    "    df_stack = pd.DataFrame()\n",
    "\n",
    "    all_id = pd.concat([train[['uid']], test[['uid']]])\n",
    "    n_folds = 10\n",
    "    df_stack['uid'] = all_id['uid']\n",
    "\n",
    "    labels = train['age'] - 1\n",
    "\n",
    "    print('LR Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=0, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('LR Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        clf = LogisticRegression(solver='sag', n_jobs=-1)\n",
    "        clf.fit(train_feature[tr], labels[tr])\n",
    "        score_va = clf.predict(train_feature[va])\n",
    "\n",
    "        score_te = clf.predict(test_feature)\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], score_va)))\n",
    "        print('Accuracy: ' + str(accuracy_score(labels[va], score_va)))\n",
    "        \n",
    "        stack_train[va, 0] = score_va + 1\n",
    "        stack_test[:, 0] += score_te + 1\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_lr_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    print('SGD Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('SGD Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        sgd = SGDClassifier(loss='log', n_jobs=-1)\n",
    "        sgd.fit(train_feature[tr], labels[tr])\n",
    "        score_va = sgd.predict(train_feature[va])\n",
    "\n",
    "        score_te = sgd.predict(test_feature)\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], sgd.predict(train_feature[va]))))\n",
    "        print('Accuracy: ' + str(accuracy_score(labels[va], score_va)))\n",
    "        \n",
    "        stack_train[va, 0] = score_va + 1\n",
    "        stack_test[:, 0] += score_te + 1\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_sgd_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    print('PAC Stacking')\n",
    "    stack_train = np.zeros((len(train), 1))\n",
    "    stack_test = np.zeros((len(test), 1))\n",
    "\n",
    "    score_va = 0\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, random_state=1024, shuffle=True)\n",
    "\n",
    "    for i, (tr, va) in enumerate(kfold.split(labels, labels)):\n",
    "        print('PAC Stacking: %d/%d' % ((i+1), n_folds))\n",
    "        pac = PassiveAggressiveClassifier(n_jobs=-1)\n",
    "        pac.fit(train_feature[tr], labels[tr])\n",
    "        score_va = pac.predict(train_feature[va])\n",
    "\n",
    "        score_te = pac.predict(test_feature)\n",
    "        print('Mean_Squared_Error: ' + str(mean_squared_error(labels[va], pac.predict(train_feature[va]))))\n",
    "        print('Accuracy: ' + str(accuracy_score(labels[va], score_va)))\n",
    "        \n",
    "        stack_train[va, 0] = score_va + 1\n",
    "        stack_test[:, 0] += score_te + 1\n",
    "\n",
    "    stack_test /= n_folds\n",
    "    stack = np.vstack([stack_train, stack_test])\n",
    "\n",
    "    df_stack['pack_tfidf_pac_classify_{}'.format('age')] = stack[:, 0]\n",
    "\n",
    "    df_stack.to_csv(dataPath+'tfidf_classfiy.csv', index=None, encoding='utf8')\n",
    "    print('Tfidf Features Stacking is Done~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish lightGBM to check K-Fold score\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.10,\n",
    "    'num_class': 6,\n",
    "    'nthread': 8\n",
    "}\n",
    "\n",
    "do_KFold = False\n",
    "\n",
    "if do_KFold:\n",
    "    kfold = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "    \n",
    "    for index, (trainIndex, testIndex) in enumerate(kfold.split(trainData, trainLabel)):\n",
    "        tr_x = trainData[trainIndex].astype(float)\n",
    "        tr_y = trainLabel[trainIndex].astype(float)\n",
    "        te_x = trainData[testIndex].astype(float)\n",
    "        te_y = trainLabel[testIndex].astype(float)\n",
    "\n",
    "        trainDataSet = lgb.Dataset(tr_x, label=tr_y)\n",
    "        testDataSet = lgb.Dataset(te_x, label=te_y)\n",
    "\n",
    "        model = lgb.train(params, trainDataSet, num_boost_round=5000,\n",
    "                          valid_sets=testDataSet, verbose_eval=100, early_stopping_rounds=100)\n",
    "\n",
    "        prediction = model.predict(te_x, num_iteration=model.best_iteration)\n",
    "\n",
    "        # Deal with float vals in prediction\n",
    "        pred = []\n",
    "        for ele in prediction:\n",
    "            pred.append(ele.tolist().index(max(ele)) + 1)\n",
    "\n",
    "        accuracy = accuracy_score(te_y+1, pred)\n",
    "        loss = mean_squared_error(te_y+1, pred)\n",
    "\n",
    "        print('KFold Iteration: %d' % index)\n",
    "        print('Accuracy: %.5f' % accuracy)\n",
    "        print('Loss: %.5f' % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's multi_logloss: 1.07277\n",
      "[200]\tvalid_0's multi_logloss: 1.0107\n",
      "[300]\tvalid_0's multi_logloss: 0.982358\n",
      "[400]\tvalid_0's multi_logloss: 0.965137\n",
      "[500]\tvalid_0's multi_logloss: 0.952621\n",
      "[600]\tvalid_0's multi_logloss: 0.942921\n",
      "[700]\tvalid_0's multi_logloss: 0.935071\n",
      "[800]\tvalid_0's multi_logloss: 0.928637\n",
      "[900]\tvalid_0's multi_logloss: 0.92243\n",
      "[1000]\tvalid_0's multi_logloss: 0.917197\n",
      "[1100]\tvalid_0's multi_logloss: 0.912417\n",
      "[1200]\tvalid_0's multi_logloss: 0.907782\n",
      "[1300]\tvalid_0's multi_logloss: 0.903474\n",
      "[1400]\tvalid_0's multi_logloss: 0.89938\n",
      "[1500]\tvalid_0's multi_logloss: 0.895299\n",
      "[1600]\tvalid_0's multi_logloss: 0.891497\n",
      "[1700]\tvalid_0's multi_logloss: 0.887762\n",
      "[1800]\tvalid_0's multi_logloss: 0.88409\n",
      "[1900]\tvalid_0's multi_logloss: 0.880554\n",
      "[2000]\tvalid_0's multi_logloss: 0.877134\n",
      "[2100]\tvalid_0's multi_logloss: 0.873929\n",
      "[2200]\tvalid_0's multi_logloss: 0.870567\n",
      "[2300]\tvalid_0's multi_logloss: 0.867378\n",
      "[2400]\tvalid_0's multi_logloss: 0.864397\n",
      "[2500]\tvalid_0's multi_logloss: 0.86134\n",
      "[2600]\tvalid_0's multi_logloss: 0.858538\n",
      "[2700]\tvalid_0's multi_logloss: 0.855496\n",
      "[2800]\tvalid_0's multi_logloss: 0.853096\n",
      "[2900]\tvalid_0's multi_logloss: 0.850127\n",
      "[3000]\tvalid_0's multi_logloss: 0.847485\n",
      "[3100]\tvalid_0's multi_logloss: 0.844674\n",
      "[3200]\tvalid_0's multi_logloss: 0.842236\n",
      "[3300]\tvalid_0's multi_logloss: 0.839539\n",
      "[3400]\tvalid_0's multi_logloss: 0.836917\n",
      "[3500]\tvalid_0's multi_logloss: 0.834898\n",
      "[3600]\tvalid_0's multi_logloss: 0.832154\n",
      "[3700]\tvalid_0's multi_logloss: 0.829552\n",
      "[3800]\tvalid_0's multi_logloss: 0.827099\n",
      "[3900]\tvalid_0's multi_logloss: 0.824493\n",
      "[4000]\tvalid_0's multi_logloss: 0.822024\n",
      "[4100]\tvalid_0's multi_logloss: 0.81961\n",
      "[4200]\tvalid_0's multi_logloss: 0.817162\n",
      "[4300]\tvalid_0's multi_logloss: 0.814789\n",
      "[4400]\tvalid_0's multi_logloss: 0.812563\n",
      "[4500]\tvalid_0's multi_logloss: 0.810225\n",
      "[4600]\tvalid_0's multi_logloss: 0.807889\n",
      "[4700]\tvalid_0's multi_logloss: 0.805598\n",
      "[4800]\tvalid_0's multi_logloss: 0.803291\n",
      "[4900]\tvalid_0's multi_logloss: 0.801058\n",
      "[5000]\tvalid_0's multi_logloss: 0.798824\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\tvalid_0's multi_logloss: 0.798824\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.10,\n",
    "    'num_class': 6,\n",
    "    'nthread': 8\n",
    "}\n",
    "\n",
    "tr_x = trainData.astype(float)\n",
    "tr_y = trainLabel.astype(float)\n",
    "te_x = testData.astype(float)\n",
    "\n",
    "trainDataSet = lgb.Dataset(tr_x, label=tr_y)\n",
    "testDataSet = lgb.Dataset(tr_x, label=tr_y)\n",
    "\n",
    "model = lgb.train(params, trainDataSet, num_boost_round=5000,\n",
    "                      valid_sets=testDataSet, verbose_eval=100, early_stopping_rounds=100)\n",
    "    \n",
    "prediction = model.predict(te_x, num_iteration=model.best_iteration)\n",
    "\n",
    "# Deal with float vals in prediction\n",
    "pred = []\n",
    "for ele in prediction:\n",
    "    pred.append(ele.tolist().index(max(ele)) + 1)\n",
    "\n",
    "test['age'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('../result/submission_tfidf.csv', header=['id', 'label'], index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
